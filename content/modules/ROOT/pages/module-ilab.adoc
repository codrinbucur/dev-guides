= AI Model Fine-Tuning - 45 minutes
:imagesdir: ../assets/images
:sectnums:
:experimental:

++++
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3HTRSDJ3M4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3HTRSDJ3M4');
</script>
++++

== Goals of this lab

As Parasol Insurance embraces the era of AI, we face a unique challenge: leveraging cutting-edge AI technology while maintaining strict control over our proprietary data and processes. This journey requires us to develop in-house AI capabilities that are as powerful as they are secure. The goal of this lab is to show you as a developer how to use open source AI tooling to fine-tune a foundation model using Parasol's proprietary data, producing an optimized and efficient LLM that can be used across a variety of use cases at Parasol. In this lab, you will:

* Explore *fine-tuning* techniques for AI models, incorporating Parasol's unique insurance expertise into LLMs
* Learn how to create and utilize a *custom knowledge base* for training AI models with organization-specific scenarios and regulations
* Apply the https://arxiv.org/abs/2403.01081[*LAB methodology*] to generate synthetic training data and specialize our model while keeping data in-house
* Gain hands-on experience in *training and serving* a customized AI model
* Understand the *benefits and limitations* of fine-tuning compared to other AI customization methods

=== Enhancing AI Models: RAG vs Fine-Tuning

When customizing AI models, two techniques stand out: Retrieval-Augmented Generation (RAG) and fine-tuning.

* *Fine-tuning* excels when you need precise, controlled outputs for specialized tasks using curated data. It's ideal for applications where security and compliance require embedding all data within the model. Fine-tuning is also suitable when you have clear use cases with specific task requirements.

image::ilab/rag-vs-finetuning-1.png[RAG vs Fine-Tuning]

* In contrast, *Retrieval-Augmented Generation (RAG)* is best when you need real-time access to dynamic knowledge bases, especially in environments with constantly updating information. RAG allows for scalability and handles out-of-domain queries effectively without the need for retraining, making it quick solution for improving model output. However, by providing contextual information to the model for each prompt, your expenses and computer resources may be higher than "baking-in" information into the model through fine-tuning.

image::ilab/rag-vs-finetuning-2.png[RAG vs Fine-Tuning]

== Get Started with Fine-Tuning

Now that we've outlined Parasol's AI needs, let's dive into the process of meeting them. In this section, we'll explore how to use the InstructLab project to tailor a foundation language model to Parasol's specific requirements, focusing on the key areas we've identified.

=== What is InstructLab?

https://instructlab.ai/[InstructLab^] is an open-source project designed to enhance large language models (LLMs) for use in generative AI applications. It provides a novel approach to model alignment and fine-tuning, allowing developers and domain experts to add new knowledge and skills to pre-trained models with minimal data and computational resources. Key features of InstructLab include:

* A taxonomy-driven approach to curating training data
* Large-scale synthetic data generation
* Iterative alignment tuning for continuous model improvement

image::ilab/instructlab-components.png[InstructLab Overview]

InstructLab is particularly useful for organizations that want to leverage private AI and keep their data in-house while still benefiting from state-of-the-art language models, without needing AI/ML or data science expertise.

As you work with InstructLab, you will see the terms _Skills_ and _Knowledge_. What is the difference between Skills and Knowledge? A simple analogy is to think of a skill as teaching someone how to fish. Knowledge, on the other hand, is knowing that the best place to catch a Bass is when the sun is setting while casting your line near the trunk of a tree along the bank.

=== Access your Virtual Environment

To begin working with InstructLab, you'll need to access the provided noNVC virtual environment. This environment comes pre-configured with all necessary tools and dependencies. Connect to {novnc_web_url}[noVNC server,window=_blank] using the password `{password}`.

==== Click the `Activities` label in the top-left corner of the screen

==== Click the `Show Applications` icon to show all the applications

==== Click the `Terminal` icon to Open a new terminal

image::ilab/launch-terminal.png[Launch Terminal]

==== Install Java 21

Run the following `sdk` command in the terminal.

[.console-input]
[source,shell,subs="+attributes,macros+"]
----
sdk install java 21.0.5-tem
----

The output should be similar to the following:

[.console-output]
[source,shell,subs="+attributes,macros+"]
----
Downloading: java 21.0.5-tem

In progress...

######################################################################### 100.0%

Repackaging Java 21.0.5-tem...

Done repackaging...

Installing: java 21.0.5-tem
Done installing!


Setting java 21.0.5-tem as default.
----

==== Build and run the Paasol Insurance application

Run the following bash script in the terminal.

[.console-input]
[source,shell,subs="+attributes,macros+"]
----
sh parasol-insurance/scripts/run-parasol-app.sh
----

This script will perform the following actions:

* Build the Quarkus (_parasol-insurnce_) application
* Run the Quarkus application locally in the REHL VM

It will take a few minutes to complete.

The output should end with the `BUILD SUCCESS` message.

==== Click the `Visual Studio Code` icon to launch Visual Studio Code

image::ilab/launch-vscode-desktop.png[Launch Podman Desktop]

==== InstructLab mainly relies on the https://github.com/instructlab/instructlab[`ilab`] command-line interface (CLI) to interact with the project

To access the `ilab` CLI, open a new terminal in Visual Studio Code by clicking on the `Terminal` menu and selecting `New Terminal`.

image::ilab/vscode-new-terminal-menu.png[Open new VSCode terminal]

include::partial-vnc-copy-paste.adoc[]

== Model Fine-Tuning for the Insurance Organization

In the next few sections, we'll walk through the process of fine-tuning an AI model using InstructLab. We'll start by setting up our environment, generating synthetic training data, training the model, and then interacting with it. We will build upon that and delve further into the biggest insurance company in North America, Parasol, which has the most extensive customer base. Parasol Insurance gets many requests to process claims, questions about different products, etc. These requests are not just internal but also external.

Parasol Insurance's primary concern is ensuring that its staff is capable of handling such requests and has access to this information through a single interface rather than going through multiple systems to scrape documents and internal portal pages. To this end, you have been tasked with adding knowledge that will aid the following use cases.

* Products and coverage (e.g., providing comprehensive policy and product information)
* Basic knowledge of the Insurance rules (e.g., offering insights on relevant local regulations)
* Responses to general claim questions and remedies (e.g., generating product-specific email templates)

image::ilab/parasol-insurance-chat.png[Parasol Insurance]

=== Preparing the Parasol Insurance Knowledge Base

The approach of fine-tuning a model allows us to shape a language model to better understand a specific domain, and fill in the gaps in its knowledge. The InstructLab taxonomy provides a structured way to guide the model fine-tuning process, enabling us to add domain-specific knowledge to the model in a heirarchical manner, similar to the example below:

image::ilab/instructlab-taxonomy.png[InstructLab Taxonomy]

Your role is crucial in this process. You'll be adding a knowledge domain to the LLM, using the organization's specific information, knowledge that the LLM doesn't have and is specific to Parasol Insurance.

=== Understanding the Knowledge Structure

Knowledge consists of data and facts and is backed by documents. When you create knowledge for a model, you're giving it additional data to more accurately answer questions. Knowledge contributions in this project contain a few things:

* A file in a https://github.com/rh-rad-ai-roadshow/parasol_knowledge[Git repository^] that holds your information. For example, these repositories can include markdown versions of information on: Parasol products, insurance domain knowledge, claims processing etc.
* A `qna.yaml` file that asks and answers questions about the information in the git repository, with desirable responses.
* An `attribution.txt` that includes the sources for the information used in the `qna.yaml`, which aids in transparency and accountability.

LLMs have inherent limitations that make certain tasks extremely difficult, like doing math problems. They're great at other tasks, like creative writing. And they could be better at things like logical reasoning. However, these limitations can be overcome by providing them with the right knowledge (and skills, https://www.youtube.com/watch?v=_kbq-npuMC0[which InstructLab can also help with^]). An LLM with knowledge helps it create a basis of information that it can learn from, then you can teach it to use this knowledge via the `qna.yaml` files.

In our case we want the LLM to learn more about Parasol Insurance by supplying this specific information in the form of a basic YAML file named `qna.yaml`:

[source,yaml]
----
version: 3<1>
domain: insurance<2>
created_by: sshaaf<3>
seed_examples:<4>
  - context: |<5>
      In the insurance industry, accurately predicting the likelihood of claims is
      essential for risk assessment and policy pricing. However, Parasol insurance
      claims datasets frequently suffer from class imbalance, where the number of
      non-claims instances far exceeds that of actual claims.
    questions_and_answers:
      - question: What is class imbalance in the context of Parasol insurance claims datasets?
        answer: |
          Class imbalance refers to the situation where the number of non-claims
          instances far exceeds that of actual claims, making predictive modeling
          difficult and potentially leading to biased models.
      - question: What types of information are included in the Policyholder Information feature?
        answer: |
          Policyholder Information includes demographic details like age, gender,
          occupation, marital status, and geographical location, which are critical
          for assessing risk.
      # more questions and answers
document_outline: |<6>
  Information about the Parasol insruance claims data glossary, terms and how
  to read and understand claims. The information is related to the Parasol
  insurance internal records and systems.
document:<7>
  repo: https://github.com/rh-rad-ai-roadshow/parasol_knowledge.git
  commit: 07227df21a3a786d15ae5b88ece2c33bd78ee36a
  patterns:<8>
    - Parasol_auto_insurance.md
    - Insurance_claims_data.md
    - teen_driving_rules.md
    - claims_cost_data.md
----

Each `qna.yaml` file requires a minimum of five question-answer pairs. The `qna.yaml` format must include the following fields:

<1> `version`: Defines the InstructLab taxonomy schema version
<2> `domain`: Category of the knowledge
<3> `created_by`: The author of the contribution, typically a GitHub username
<4> `seed_examples`: Five or more examples sourced from the provided knowledge documents, representing a `question` for the model and desired `response`
<5> `context`: A chunk of information from the knowledge document.
<6> `document_outline`: An outline of the document containing the knowledge you're adding to the model.
<7> `document`: The source of your knowledge contribution, consisting of a `repo` URL pointing to the knowledge markdown files, and `commit` identifier for the specific commit that contains the files
<8> `patterns`: A list of glob patterns specifying the markdown files in your repository that should be used during training. We have placed all the knowledge documents in the https://github.com/rh-rad-ai-roadshow/parasol_knowledge[parasol-knowledge] repository.

=== Creating the Parasol Insurance Knowledge Base

Now that we understand the constructs of the taxonomy's knowledge, let's go ahead and create our knowledge base, which we will then feed into the LLM to train. This will help our applications that utilize the LLM, and agents directly chatting with the model. Furthermore, it will help with claims processing, fraud detection, or anyone who would like to ask the LLM about products, coverage, laws, and some information about Parasol itself. Let's get started!

==== Open the `instructlab` taxonomy directory in Visual Studio Code

Open VSCode by running the below command. Even if you already have VSCode open, you should run this command to open the taxonomy folder (notice the `--reuse-window` flag).

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
code ~/.local/share/instructlab/taxonomy --reuse-window
----

If you are prompted to create a new _keyring_ passcode, simply enter any password here (you won't need this again):

image::ilab/ilab-keyring.png[Keyring]

[start=2]
==== With the new window open, you can select *Yes, I trust the authors* to proceed

image::ilab/vscode-trust-authors.png[Trust Authors]

[start=3]
==== Navigate to the `knowledge/` folder

This file will contain the questions and answers that will be used to train the model.

==== Create a structure for Parasol insurance knowledge

To do that create folders by first right clicking on the `Knowledge` folder, and then pressing `New Folder`, as shown in the screen shot below

image::ilab/ilab-taxanomy-create-folder.png[New Folder]

We should create a knowledge folder structure that we can add to later as we add more knowledge and for our peers to also understand how its structured. Lets create a structure like this `knowledge > economy > finance > insurance > parasol`. In VSCode this is quite easy.

==== In the field as shown in the image below type `economy/finance/insurance/parasol`

image::ilab/ilab-taxonomy-create-folder2.png[New folder]

Perfect, now we have the basic working structure to add in specific knowledge about our organization.

== Curating the Data for our AI Model

Let's now add the following taxonomy knowledge file for Parasol Insurance. Each section of this file addresses different aspects of Parasol's insurance policies:

* Like any insurance company on the planet, data is stored into multiple systems, files etc. Employees at Parasol Insurance either using the system for the first time or using it for e.g. detecting fraud, trying to understand the glossary, acronyms etc. A good example is `Policy ID`, a unique ID for policy in our database systems. The LLM does not know about this. By adding this, we can ensure that once a claims agent or an application asks about a policy ID, the LLM can give reasonable answers and suggestions.

* Information about the Parasol Insurance company, and an overview of product details. This will enable the LLM to give answers on a high level about the different offerings, formulate a context about Parasol Insurance, its history, etc.

* Information specific to policies in relation to the different products. This will help our claims processing agents to ask questions about specific cases and scenarios to the LLM. The LLM should be able to suggest remedies or further knowledge to look into.

The questions covered in the questions & answered should be answerable through the knowledge document(s) defined at the end of this file.

=== Create knowledge file

Copy the following and add it as a new file called `qna.yaml` in the folder `parasol` as shown in the image above. "qna" is short for "questions and answers". To do this, right-click on `parasol` folder name and select `New File...`:

image::ilab/ilab-taxonomy-qna.png[New folder]

Enter the filename `qna.yaml` to create the file. Then, copy in the following content into the file (using the special copy/paste procedure as before):

[.console-input]
[source,yaml,subs="+attributes,macros+"]
----
include::https://raw.githubusercontent.com/rh-rad-ai-roadshow/parasol-taxonomy/refs/heads/main/knowledge/economy/finance/insurance/parasol/qna.yaml[]


aaa
----

And now lets also create an attribution.txt file for citing sources. Copy the following and create a new file `attribution.txt` in the same folder `parasol`:

[.console-input]
[source,yaml]
----
include::https://raw.githubusercontent.com/rh-rad-ai-roadshow/parasol-taxonomy/refs/heads/main/knowledge/economy/finance/insurance/parasol/attribution.txt[]
----

=== Check that the Taxonomy is Recognized by InstructLab

Now that we've added data, let's check that the taxonomy is recognized by InstructLab. This will help us ensure that the data we've added is valid and can be used to generate synthetic training data.

We're going to run some commands from the terminal, so from the `Terminal` menu, select `New Terminal` to open a new terminal window (or use the terminal you already have open).

image::ilab/vscode-new-terminal-menu.png[Open new VSCode terminal]

Let's navigate to the `instructlab` directory:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
cd ~/instructlab
----

Now, activate the Python virtual environment:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
source venv/bin/activate
----

Run the following command to check the validity of the taxonomy:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
ilab taxonomy diff
----

After running the above command you should be able to see the following output.

[source,bash]
----
knowledge/economy/finance/insurance/parasol/qna.yaml
Taxonomy in /home/instruct/.local/share/instructlab/taxonomy is valid :)
----

NOTE: If you see an error such as `no new line character at the end of the file`, simply place your cursor at the end of the last line of the taxonomy file and press kbd:[ENTER] to add a new line, and re-run the `ilab diff` command.

If you do not see output similar to above, you may not have added in all of the Q&A file. This is important as the model will use this file to generate synthetic data in the next section.

== Generating Synthetic Training Data & Training the New Model

Now that we've added some initial data, let's use InstructLab to generate synthetic training data. Large Language Models inherently require a large amount of data to be effective, and it can be difficult to find enough real-world data for a niche domain. However, by using InstructLab, we can generate synthetic data that can be used to train the model.

=== Open a terminal in Visual Studio Code

image::ilab/vscode-new-terminal-menu.png[Open new VSCode terminal]

=== Run the following command to generate synthetic training data

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
cd ~/instructlab
----

=== Activate the Python virtual environment

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
source venv/bin/activate
----

=== Run the data generation command:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
ilab data generate --model ~/instructlab/models/granite-7b-lab-Q4_K_M.gguf --sdg-scale-factor 1 --enable-serving-output
----

To reduce the amount of time the generation process takes, we are setting the *"--sdg-scale-factor"* to `1` (The number of instructions to generate for each seed
example), the default for this value is `30`. If we were generating data for a production deployment we would likely set this value higher.

This process may take some time (up to 25 minutes for this lab), depending on the amount of data and the computational resources available. Feel free to wait, or stop the process with kbd:[CTRL+C] as we will not be using these files in the next step in the interest of time. You may also want to open a separate Terminal and run the `nvtop` command to see the use of your GPU during this generation phase. Click the `+` button and run `nvtop` in the new terminal:

image::ilab/nvtop.png[nvtop]

You can switch back to the original terminal by clicking on it on the right side of the screen (named `python`) to check on the progress of the generation.

[NOTE]
====
If you encounter an *AssertionError*, this is likely due to a known issue that has been resolved in the latest InstructLab. The fix will be included in the next release.
====

Once the generation stage is complete, you should see something like this:

[source,console]
----
$ ilab data generate --model ~/instructlab/models/granite-7b-lab-Q4_K_M.gguf --sdg-scale-factor 1 --enable-serving-output
Filter: 100%|████████████████████████████████████████████████| 42/42 [00:00<00:00, 2836.45 examples/s]
Filter: 100%|████████████████████████████████████████████████| 28/28 [00:00<00:00, 4355.46 examples/s]
Flattening the indices: 100%|████████████████████████████████| 22/22 [00:00<00:00, 3207.77 examples/s]
Map: 100%|███████████████████████████████████████████████████| 22/22 [00:00<00:00, 2485.04 examples/s]
Flattening the indices: 100%|████████████████████████████████| 20/20 [00:00<00:00, 2395.65 examples/s]
Casting to class labels: 100%|███████████████████████████████| 20/20 [00:00<00:00, 1306.68 examples/s]
INFO 2024-10-02 16:47:28,764 instructlab.sdg.eval_data:126: Saving MMLU Dataset /home/instruct/.local/share/instructlab/datasets/node_datasets_2024-10-02T16_21_57/mmlubench_knowledge_economy_finance_insurance_parasol.jsonl
Creating json from Arrow format: 100%|█████████████████████████████████| 1/1 [00:00<00:00, 567.10ba/s]
INFO 2024-10-02 16:47:28,780 instructlab.sdg.eval_data:130: Saving MMLU Task yaml /home/instruct/.local/share/instructlab/datasets/node_datasets_2024-10-02T16_21_57/knowledge_economy_finance_insurance_parasol_task.yaml
Map:   0%|                                                             | 0/722 [00:00<?, ? examples/s]WARNING 2024-10-02 16:47:28,802 instructlab.sdg.datamixing:223: Failed to split generated q&a: Parasol Insurance Company', founded in 1936 by James Falkner and James Labocki, is one of the largest and most well-known auto insurance companies in the United States, offering various insurance products for personal vehicles, motorcycles, homeowners, renters, boats, RVs, life insurance, business insurance, and identity theft protection. Parasol is known for its memorable advertising campaigns, user-friendly digital platforms, and competitive pricing, as well as its strong financial strength indicated by high ratings from agencies like A.M. Best.
----

The result of this is a number of files which you can inspect in the `~/.local/share/instructlab/datasets` directory. These files are used in the following _training_ phase. Open this directory by running the following command in the Terminal:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
xdg-open ~/.local/share/instructlab/datasets
----
you can examine the contents of the files by double-clicking on them. For example, check out the file whose name starts with `messages_merlinite`. These are sample questions generated based on the content of our Parasol data.

=== Training the Model with New Data

With our synthetic data generated, we should now be in a position to train the model.  Because we only created 1 sample and due to time constraints we're not going to perform the actual training in this lab.

If we were to do this, we would again use the "ilab" CLI with the "model train" command. Something like `ilab model train --device cuda`. Depending on the hardware available, this can take anywhere from several minutes to several hours or days. Once this process was finished we would then have a model we can serve locally with ilab to test our results.

=== Serve the new Model

We have provisioned a trained model in the folder `~/instructlab/models` called `parasol-model.gguf`. Serve this model by running the following command in the terminal:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
ilab model serve --model-path ~/instructlab/models/parasol-model.gguf
----
It may take a minute to start, but you should see the following:

[source,bash]
----
INFO instructlab.model.serve:136: Using model '/home/instruct/instructlab/models/parasol-model.gguf' with -1 gpu-layers and 4096 max context size.
INFO instructlab.model.serve:140: Serving model '/home/instruct/instructlab/models/parasol-model.gguf' with llama-cpp
INFO instructlab.model.backends.llama_cpp:232: Replacing chat template:
 {% for message in messages %}
{% if message['role'] == 'user' %}
{{ '<|user|>
' + message['content'] }}
{% elif message['role'] == 'system' %}
{{ '<|system|>
' + message['content'] }}
{% elif message['role'] == 'assistant' %}
{{ '<|assistant|>
' + message['content'] + eos_token }}
{% endif %}
{% if loop.last and add_generation_prompt %}
{{ '<|assistant|>' }}
{% endif %}
{% endfor %}
INFO instructlab.model.backends.llama_cpp:189: Starting server process, press CTRL+C to shutdown server...
INFO instructlab.model.backends.llama_cpp:190: After application startup complete see http://127.0.0.1:8000/docs for API.
----

=== Interacting with the Model

To chat, open a new terminal using the `+` button above the terminal:

image::ilab/second-terminal.png[Launch Activities]

In the new terminal, run the following command to begin a chat session with the model:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
cd ~/instructlab
source venv/bin/activate
ilab model chat
----

We can now ask the trained model some parasol specific questions such as:

- Does Parasol insurance policies include  loss of income cover if the insured driver is at fault?
- Will Parasol insurance cover the cost of car rental if my car is undriveable as a result of an accident?
- What is Apex plus from parasol insurance?

image::ilab/new-model-responses.png[Launch Activities]

The answers are specific to Parasol's policies and demonstrate the ability for organizations to fine-tune models with their own data, to improve the accuracy of responses, which can be used in many use cases.

=== Bonus: Graphical UI

In reality, Parasol employees would not be using `ilab` to ask the model(s) questions. For this lab, feel free to use the same application you may have seen in other exercises in this workshop. To open the application, run the following command in your Terminal:

[.console-input]
[source,bash]
----
xdg-open http://localhost:8005
----
This is the same Java application built on https://quarkus.io[Quarkus^] which Parasol customer service reps use to organize claims. On the *Claims* page, click on the first Claim for the customer named _Marty McFly_.

image::ilab/mcfly-1.png[App]

Click on the assistant chat tool at the lower right and enter the same prompts as before.

image::ilab/mcfly-tool.png[App]

Try this one as well:

[.console-input]
[source,console,subs="+attributes,macros+"]
----
Should Parasol approve this claim?
----

and

[.console-input]
[source,console,subs="+attributes,macros+"]
----
Who was at fault?
----

image::ilab/mcfly-2.png[App]

In this case, the claim information is also included in the prompt, in addition to your questions, so that the assistant can make reasonable answers based on the claim in question!

== Conclusion

This exercise showed how organizations can leverage fine tuning with InstructLab to improve the accuracy of LLM responses. Here's a quick summary of what we have learned:

* You Learned about *fine-tuning* techniques for AI models, incorporating Parasol's unique insurance expertise into LLMs
* Your also learned how to create and utilize a *custom knowledge base* for training AI models with organization-specific scenarios and regulations
* Apply the https://arxiv.org/abs/2403.01081[*LAB methodology*] to generate synthetic training data and specialize our model while keeping data in-house
* You gained hands-on experience in *training and serving* a customized AI model
* You understand the *benefits and limitations* of fine-tuning compared to other AI customization methods

These skills and tools will be invaluable as you continue to develop AI-enabled applications at Parasol Insurance, allowing you to quickly iterate on ideas and integrate powerful AI capabilities into your workflow.