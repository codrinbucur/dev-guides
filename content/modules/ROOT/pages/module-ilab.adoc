= Model Fine-tuning with InstructLab - x minutes
:imagesdir: ../assets/images
:sectnums:

++++
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3HTRSDJ3M4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3HTRSDJ3M4');
</script>
++++

// Table of Contents & Work Responsibilities :)

// 1. Get Started with InstructLab [Cedric/Shaaf]
// 1.1. What is InstructLab [Cedric/Shaaf]
// 1.2. Access Virtual Environment [Cedric/Shaaf]
// 2. Hands on with AI Model Fine-tuning [Cedric]
// 2.1. Starting from Example Data in VSCode (ex. 5 instructions) [Cedric]
// 2.2. Generating Synthetic Training Data [Cedric]
// 2.3. Training the Model with New Data [Cedric]
// 2.4. Interacting with the Model [Cedric]
// 3. Model Training for the Insurance Organization [Shaaf]
// 3.1. Viewing the Synthetic Data Generated [Shaaf]
// 3.2. Training the Model (15 mins) [Shaaf]
// 3.3. Interacting with the Model [Shaaf]
// 4. Integrating the Model in the Application Development Workflow [Cedric]
// 4.1 Loading the Model in Podman Desktop [Cedric]
// 4.2 Sharing the Model beyond the local environment [Shaaf]

== Adopting AI for an Enterprise Use Case

As Parasol Insurance embraces the era of AI, we face a unique challenge: leveraging cutting-edge AI technology while maintaining strict control over our proprietary data and processes. This journey requires us to develop in-house AI capabilities that are as powerful as they are secure.

Our path forward involves three critical steps:

. Knowledge Infusion
* How do we incorporate Parasol's unique insurance expertise into AI models?
. Model Customization
* How can we fine-tune AI to address Parasol-specific scenarios and regulations?
. Secure Deployment
* What's the best way to integrate AI into our workflow while keeping data in-house?

// image::instructlab/parasol-ai-journey.png[Parasol's Private AI Journey]

== Goals of this lab

In this hands-on session, you'll dive into the world of private AI development for the enterprise setting. By the end of this lab, you will:

* *Understand* the fundamentals of fine-tuning and its role in creating customized, private AI models.
* *Create* a Parasol-specific model by using the open source project InstructLab with a small amount of human-curated seed data.
* *Generate* synthetic training data to effectively adapt a general-purpose model for Parasol's unique insurance scenarios.
* *Train* a Large Language Model (LLM) locally with Parasol's proprietary information.
* *Interact* with the newly trained model to verify its new domain-specific capabilities.
* *Serve* the customized model locally before moving to production with our organization's secure infrastructure on OpenShift AI.

=== Enterprise Needs for an AI Model

This lab will equip you to enhance Parasol's AI capabilities in three key areas:

1. Generating product-specific email templates
2. Providing comprehensive policy and product information
3. Offering insights on relevant local regulations

Through fine-tuning, you'll learn how to provide an LLM accurate and relevant information to provide more efficient, accurate, and compliant customer service.

== Get Started with Fine-tuning

Now that we've outlined Parasol's AI needs, let's dive into the process of meeting them. In this section, we'll explore how to use the InstructLab project to tailor a pre-trained language model to Parasol's specific requirements, focusing on the key areas we've identified.

=== What is InstructLab?

https://instructlab.ai/[InstructLab] is an open-source project designed to enhance large language models (LLMs) for use in generative AI applications. It provides a novel approach to model alignment and fine-tuning, allowing developers and domain experts to add new knowledge and skills to pre-trained models with minimal data and computational resources. Key features of InstructLab include:

* A taxonomy-driven approach to curating training data
* Large-scale synthetic data generation
* Iterative alignment tuning for continuous model improvement

image::ilab/instructlab-components.png[InstructLab Overview]

InstructLab is particularly useful for organizations like Parasol that want to leverage private AI and keep their data in-house while still benefiting from state-of-the-art language models.

=== Access your Virtual Environment

To begin working with InstructLab, you'll need to access the provided noNVC virtual environment. This environment comes pre-configured with all necessary tools and dependencies: {novnc_url}[*{novnc_url}*,window=_blank], using the password `{password}`.

. Click the `Activities` label in the top-left corner of the screen.

// REMOVE Once CI is updated

. CLick on "Terminal"

Enter the following commands

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
curl -L -o files/vscode.rpm 'https://code.visualstudio.com/sha/download?build=stable&os=linux-rpm-x64'
sudo dnf install xdg-utils
sudo rpm -ivh files/vscode.rpm
sudo dnf -y install zip gcc glibc-devel zlib-devel 
curl -s "https://get.sdkman.io" | bash
source "/home/instruct/.sdkman/bin/sdkman-init.sh"
sdk install java 21.0.3-tem
pip install 'numpy<2.0'

cat <<EOF >> /home/instruct/instructlab/config.yaml
chat:
  context: default
  greedy_mode: false
  logs_dir: data/chatlogs
  max_tokens: null
  model: models/merlinite-7b-lab-Q4_K_M.gguf
  session: null
  vi_mode: false
  visible_overflow: true
general:
  log_level: INFO
generate:
  chunk_word_count: 1000
  model: models/merlinite-7b-lab-Q4_K_M.gguf
  num_cpus: 10
  num_instructions: 100
  output_dir: generated
  prompt_file: prompt.txt
  seed_file: seed_tasks.json
  taxonomy_base: origin/main
  taxonomy_path: taxonomy
serve:
  gpu_layers: -1
  host_port: 127.0.0.1:8000
  max_ctx_size: 4096
  model_path: models/merlinite-7b-lab-Q4_K_M.gguf
EOF
----

// End of Remove block


. Click the `Show Applications` icon to show all the applications.

. Click the `Visual Studio Code` icon to launch Visual Studio Code.

image::ilab/launch-vscode-desktop.png[Launch Podman Desktop]

// [start=4]

. We're going to run some commands from the terminal, so from the `Terminal` menu, select `New Terminal` to open a new terminal window.

image::ilab/vscode-new-terminal-menu.png[Open new VSCode terminal]

== Hands on with AI Model Fine-tuning

In this section, we'll walk through the process of fine-tuning an AI model using InstructLab. We'll start by setting up our environment, generating synthetic training data, training the model, and then interact with it.

=== Adding training data to the Taxonomy

The InstructLab taxonomy is a structured knowledge base that guides the model fine-tuning process. By customizing the taxonomy, we can add domain-specific knowledge to the model.

. Open the `instructlab` directory in Visual Studio Code through the terminal:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
code -r .
----

. Navigate to the `taxonomy/knowledge/technology` folder  and create a `qna.yaml` file in the editor. This file will contain the questions and answers that will be used to train the model.

. Add the following question and answer pair sto the `qna.yaml` file and save the changes.

[source,yaml]
----

created_by: Marty_McFly
domain: parasol
seed_examples:
- answer: The DeLorean was manufactured from 1981 to 1983.
  question: When was the DeLorean manufactured?
- answer: The DeLorean Motor Company manufactured the DeLorean DMC-12.
  question: Who manufactured the DeLorean DMC-12?
- answer: Transmission Repair costs between $2,500 and $4,000 for the Delorean DMC-12.
  question: How much does it cost to repair the transmission on a DeLorean DMC-12?
- answer: The top speed of the DeLorean DMC-12 was 110MPH and the 0-60 time was approximately 8.8 seconds.
  question: How fast was the Delorean DMC-12?
- answer: The DeLorean DMC-12 weighs 2,712lb (1,230kg).
  question: How much does the DeLorean DMC-12 weigh?
- answer: Maintenance on a DeLorean DMC-12 includes regular oil changes every 3,000 miles or 3 months,
    brake fluid change every 2 years, transmission fluid changes every 30,000 miles, coolant change every 2 years,
    and regularly checking the battery for corrosion and proper connection.
  question: What does maintenance for a DeLorean DMC12 look like?
- answer: It costs between $800 and $1000 to repair the suspension on a DeLorean DMC-12.
  question: How much does it cost to repair the supension on a DeLorean DMC-12?
task_description: 'Details on instructlab community project'
document:
  repo: https://github.com/gshipley/backToTheFuture.git
  commit: 8bd9220c616afe24b9673d94ec1adce85320809c
  patterns:
    - data.md
----

This is a simple example of a question and answer pair that will be used to train the model, through the synthetic data generation process performed later.

=== Generating Synthetic Training Data


Now that we've added some initial data, let's use InstructLab to generate synthetic training data.

. Open a terminal in Visual Studio Code.
. Run the following command to generate synthetic training data:
+
[source,bash]
----
cd ~/instructlab
----
. Activate the Python virtual environment:
+
[source,bash]
----
source venv/bin/activate
----
. Run the data generation command:
+
[source,bash]
----
ilab data generate  --num-instructions 5
----

To reduce the amount of time the generation process takes, we are setting the "--num-instructions" flag to "5", the default for this value is "100". If we were generating data for a production deployment we would likely set this value even higher.

This process may take some time, depending on the amount of data and the computational resources available. 

Once the generation stage is complete, you should see something like
[source,bash]
----

Q> How long does it take to accelerate to 88 miles per hour in a DeLorean DMC-12?
I> 
A> Approximately 8.8 seconds is needed to reach 88 mph in a Delorean DMC-12.

 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 4/5 [01:05<00:16, 16.51s/it]INFO 2024-09-05 18:49:21,781 generate_data.py:505: generate_data Selected taxonomy path knowledge->technology
INFO 2024-09-05 18:49:24,075 generate_data.py:505: generate_data Selected taxonomy path knowledge->technology
INFO 2024-09-05 18:49:26,285 generate_data.py:505: generate_data Selected taxonomy path knowledge->technology
INFO 2024-09-05 18:49:28,449 generate_data.py:505: generate_data Selected taxonomy path knowledge->technology
Q> What does the term “Flux capacitor” refer to in the context of a DeLorean DMC-12?
I> 
A> The term “Flux capacitor” refers to a component that enables time travel on a DeLorean DMC-12.

100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:25<00:00, 17.01s/it]
INFO 2024-09-05 18:49:41,814 generate_data.py:609: generate_data 5 instructions generated, 4 discarded due to format (see generated/discarded_merlinite-7b-lab-Q4_K_M_2024-09-05T18_48_16.log), 0 discarded due to rouge score
INFO 2024-09-05 18:49:41,815 generate_data.py:613: generate_data Generation took 85.28s

----

We can examine the output of the generation stage by taking a look at the "generated" folder in ~/instructlab

within this folder you'll see 4 different files

* discarded_merlinite-7b-lab-Q4_K_M_DATETIME.log: This contains a log of any generated instructions which were discarded during the generation process for any reason e.g. "didn't match expected format"
* generated_merlinite-7b-lab-Q4_K_M_DATETIME.json: This contains the list of generated instructions plus context with which the model training instructions will be created
* test_merlinite-7b-lab-Q4_K_M_DATETIME.jsonl: This file contains test prompts and responses which are used at the end of the training process
* train_merlinite-7b-lab-Q4_K_M_DATETIME.jsonl: This file contains the instructions used during the train process to train the model.


=== Training the Model with New Data

With our synthetic data generated, we should now be in a position to train the model.  Because we only created 5 sample instructions and due to time contrainsts we're not going to perform the actual training in this lab.

If we where to do this, we would again use the "ilab" CLI with the "model train" command

Once this process was finished we would then have a model we can serve locally with ilab to test our results.

== Training the Model for the Insurance Organization

In the previous section, we learned the basics of InstructLab by adding knowledge, generating synthetic data, and finally, training the model. This gives us the basic understanding. In this section, we will build upon that and delve further into the biggest insurance company in North America, Parasol, which has the most extensive customer base. Parasol Insurance gets many requests to process claims, questions about different products, etc. But these requests are not just internal but also external. 

Parasol Insurance's primary importance is ensuring that its staff is capable of handling such requests and has access to this information through a single interface rather than going through multiple systems for scrapping through documents and internal portal pages. To this effect, you have been tasked to add knowledge that will aid the following use cases. 

. Products and coverage
. Basic knowledge of the Insurance rules
. Responses to general claim questions and remedies.

=== Preparing the Parasol Insurance Knowledge Base

As part of this process, your role is crucial. You must first add a knowledge domain to the LLM. We will follow a procedure similar to the one in the previous section and add more comprehensive knowledge for the use cases. 

`git`. Let's go ahead and pull that knowledge before we get into the training process.
Assuming that you have VSCode already open. Open a new Terminal window by clicking

image::ilab/vscode-new-terminal-menu.png[Open new VSCode terminal]

Run the following commands into the terminal. 
[.console-input]
[source,adoc]
----
cd taxonomy
git remote -v
----

In the above commands we first change directory to the taxonomy, this is where InstructLab has installed the default taxonomy which is also available on https://github.com/instructlab/taxonomy.git[*github*^]. The second command shows us the remote git repository we have configured on our local machine, which is also the default. You should be able to see the following output from the above commands.

[.console-output]
[source,adoc]
----
origin	https://github.com/instructlab/taxonomy.git (fetch)
origin	https://github.com/instructlab/taxonomy.git (push)
----

=== Configuring the Parasol Taxonomy Repository

Next we want to be able to add our own private Parasol taxonomy and train our models with it. To do that we will configure instructLab taxonomy with the following two commands. The command will configure the remote repository, and the second command prints the git repository configuration.

// This repository won't work, the knowledge is updated to version 3

[.console-input]
[source,adoc]
----
git remote add parasol https://github.com/rh-rad-ai-roadshow/parasol-taxonomy.git
git remote -v
----

The command output should look as follows. And this means we have now successfully configured our private taxonomy repository.

[.console-output]
[source,adoc]
----
origin	https://github.com/instructlab/taxonomy.git (fetch)
origin	https://github.com/instructlab/taxonomy.git (push)
parasol	https://github.com/rh-rad-ai-roadshow/parasol-taxonomy.git (fetch)
parasol	https://github.com/rh-rad-ai-roadshow/parasol-taxonomy.git (push)
----

Let's go ahead and pull the changes.
[.console-input]
[source,adoc]
----
git pull parasol main
----
The commad should show an output similar to the following image. It shows the different taxonomy files that are additional to the current default taxonomy. 

image::ilab/terminal-pull-parasol-taxonomy.png[Parasol taxonomy pull git]

Lets take a look at the files that have been pulled in from our private Parasol Insurance taxonomy. You will be able to find these files under `knowledge > economy > finance > insurance` as shown in the following screenshot.

image::ilab/parasol-taxonomy-structure.png[InstructLab taxonomy structure]

=== Understanding the Knowledge Structure

Knowledge consists of data and facts and is backed by documents. When you create knowledge for a model, you're giving it additional data to more accurately answer questions.

Knowledge contributions in this project contain a few things.

- A file in a https://github.com/rh-rad-ai-roadshow/parasol_knowledge[git repository] that holds your information. For example, these repositories can include markdown versions of information on: Parasol products, insurance domain knowledge, claims processing etc.
- A `qna.yaml` file that asks and answers questions about the information in the git repository.
- An `attribution.txt` that includes the sources for the information used in the qna.yaml.

LLMs have inherent limitations that make certain tasks extremely difficult, like doing math problems. They're great at other tasks, like creative writing. And they could be better at things like logical reasoning.

An LLM with knowledge helps it create a basis of information that it can learn from, then you can teach it to use this knowledge via the qna.yaml files. In our case we want the LLM to learn more about Parasol Insurance. 

A knowledge file looks as follows: 

[.console-input]
[source,yaml]
----
version: 2
task_description: "Teach a model more details about Parasol Insurance"
created_by: sshaaf
domain: insurance
seed_examples:
  - question: What is class imbalance in the context of Parasol insurance claims datasets?
    answer: |
      Class imbalance refers to the situation where the number of non-claims instances far exceeds
      that of actual claims, posing challenges for predictive modeling.

document:
  repo: https://github.com/sshaaf/parasol_knowledge.git
  commit: b87677d
  patterns:
    - Insurance_claims_data.md
----

Each `qna.yaml` file requires a minimum of five question-answer pairs. The `qna.yaml` format must include the following fields:

- `version`: The value must be the number 2.
- `task_description`: An optional description of the knowledge.
- `created_by`: Your GitHub username.
- `domain`: Category of the knowledge.
- `seed_examples`: Five or more examples sourced from the provided knowledge documents.
  - `question`: A question for the model. This key is required.
  - `answer`: The desired response from the model. This key is required.
- `document`: The source of your knowledge contribution.
  - `repo`: The URL to your repository that holds your knowledge markdown files.
  - `commit`: The SHA of the commit in your repository with your knowledge markdown files.
  - `patterns`: A list of glob patterns specifying the markdown files in your repository. Any glob pattern that starts with `*`, such as `*.md`, must be quoted due to YAML rules. For example, `"*.md"`. In our case we have placed all the knowledge documents in the https://github.com/rh-rad-ai-roadshow/parasol_knowledge[parasol-knoledge] repository.

Let’s now examine the taxonomy knowledge files for Parasol Insurance. Open each file listed and observe the questions.

==== Knowledge File: Driving Age
// - **Driving age**: 

These are question-and-answer pairs for driving rules in Alaska and New Hampshire. One document file has been added to these questions so that LLM has more context. You can inspect this document in the Parasol Knowledge repository https://github.com/rh-rad-ai-roadshow/parasol_knowledge/blob/main/teen_driving_rules.md[here].

image::ilab/parasol-knowledge-taxonomy-drivingage.png[InstructLab taxonomy structure]

==== Knowledge File: Parasol Claims Data
// - **Parasol claims data**

Here, we are adding information about the different terms and glossary for a claim specific to Parasol Insurance and its databases. A good example is `Policy ID,` a unique ID for policy in our database systems. The LLM does not know about this. By adding this, we can ensure that once a claims agent or an application asks about a policy ID, the LLM can give reasonable answers and suggestions. In our next section, we will learn more about analyzing data and craft prompts in more detail.
You can inspect the addtional knowledge document in the Parasol Knowledge repository https://github.com/rh-rad-ai-roadshow/parasol_knowledge/blob/main/Insurance_claims_data.md[here].

image::ilab/parasol-knowledge-taxonomy-claimsdata.png[InstructLab taxonomy structure]

==== Knowledge File: Parasol Insurance Overview
// - **Parasol insurance**

Here, we are adding some basic information about Parasol Insurance, an overview of product details. This will enable the LLM to give answers on a high level about the different offerings, fomulate a context about Parasol Insurance, history etc. 
You can inspect the addtional knowledge document in the Parasol Knowledge repository https://github.com/rh-rad-ai-roadshow/parasol_knowledge/blob/main/Parasol_auto_insurance.md[here].

image::ilab/parasol-knowledge-taxonomy-insurance.png[InstructLab taxonomy structure]

==== Knowledge File: Parasol Policies
// - **Parasol policies**

Here, we are adding information specific to policies in relation to the different products. This will help our claims processing agents to ask questions about specific cases and scenarios to the LLM. The LLM should be able to suggest remedies or further knowledge to look into.
You can inspect the addtional knowledge document in the Parasol Knowledge repository https://github.com/rh-rad-ai-roadshow/parasol_knowledge/blob/main/Parasol_auto_insurance.md[here].

image::ilab/parasol-knowledge-taxonomy-products.png[InstructLab taxonomy structure]

=== Synthetic data generation

We can now perform the synthetic data generation from our new knowledge

. Open a terminal in Visual Studio Code.
. Run the following command to generate synthetic training data:
+
[source,bash]
----
cd ~/instructlab
----
. Activate the Python virtual environment:
+
[source,bash]
----
source venv/bin/activate
----
. Run the data generation command:
+
[source,bash]
----
ilab data generate  --num-instructions 5
----

=== Training the Model

As with the previous example, we're not going to perform the model training in this section due to time constraints.  


=== Interacting with the Model

We have provisioned a trained model in the folder `~/instructlab/models` called `parasol-model.gguf`

. We can serve this model with the command
. Run the data generation command:
+
[source,bash]
----
ilab model serve --model-path ~/instructlab/models/parasol-model.gguf
----

We can now ask the trained model some parasol specific questions such as:

- Who founded parasol insurance?

- Will Parasol insurance cover the cost of car rental if my car is undriveable as a result of an
 accident?