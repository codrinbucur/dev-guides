= Private Docs (RAG/Tools) - x minutes
:imagesdir: ../assets/images
:sectnums:

++++
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3HTRSDJ3M4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3HTRSDJ3M4');
</script>
++++

== Integrating AI into an Existing Application

Parasol Insurance is looking to not only build new apps but also integrate generative AI into their existing applications, such as their customer service representative tools used to respond to customer claim emails. In this exercise, you will:

* Dive into advanced application integration techniques for AI, exploring how to *integrate* AI into applications for Parasol's unique needs
* Learn how to ingest and utilize *private* documents securely
* Apply the *Retrieval-Augmented Generation* (RAG) pattern to enhance AI model output
* Extend AI models with specialized *tools and agents*
* Understand the *limitations* of RAG and when to consider fine-tuning

This module will focus on *Building and Refining*.

image::private-docs/building-gen-ai.png[Adopting Gen AI]

IMPORTANT: If you haven't accessed *Red Hat Developer Hub and Red Hat Dev Spaces* yet, complete the following sections. Otherwise, *proceed* to the <<skip-prereqs, Working in your Cloud-based Development Environment>> section.

include::partial-devhub-pre-req.adoc[]
include::partial-cicd-pre-req.adoc[]
include::partial-dev-spaces-pre-req.adoc[]

[#skip-prereqs]
== Working in your Cloud-based Development Environment

https://developers.redhat.com/products/openshift-dev-spaces/overview[Red Hat OpenShift Dev Spaces^] is a cloud-based development environment built on top of Kubernetes and containers. It offers a streamlined and secure way for developers to code, build, and test applications directly within the OpenShift ecosystem. You'll use the Dev Spaces environment in this module to enhance the current functionality of the Parasol Insurance application.

=== Using LangChain4j with Quarkus

You'll be building new features in this application, based on https://developers.redhat.com/products/quarkus/overview[Quarkus^] and the https://github.com/langchain4j/langchain4j[LangChain4j^] library. The https://quarkus.io/extensions/?search-regex=langchain[Quarkus LangChain4j extensions^] bridge the gap between your Quarkus application and LangChain4j, a library that allows interaction with various LLMs like OpenAI, Hugging Face, or Ollama. It has the following key features and benefits:

** *Simplified LLM Integration*: The extension streamlines the process of incorporating LLMs into your application, saving development time and effort.
** *Declarative AI Services*: Defines how you want to interact with the LLM using annotations or configuration files.
** *Embedding Support*: Integrates with document embedding stores like Redis, Chroma, or Infinispan to store and retrieve document context for the LLM.
** *Observability Integration*: Allows monitoring and logging of LLM interactions within your Quarkus application.

=== Understanding the application's codebase

This Quarkus application is a customer service processing tool that handles customer claim emails for Parasol insurance. The team has recently improved the application with a chatbot to interact with the agent and to generate responses based on the email content. In the VS Code environment, navigate to the `src/main/java/org/parasol` directory, which contains the main source code of the application.

image::private-docs/quarkus-codebase.png[Quarkus codebase]

In the `src/main/java/org/parasol/ai/ClaimService.java` file, you'll find the main AI chatbot class that processes the customer claim emails with a `@SystemMessage` and `@UserMessage` annotation, and a `chat` method. The `chat` method processes the claim details and question, then generates a response based on the claim and references provided.

image::private-docs/claim-service-code.png[ClaimService code]

You can also explore the `src/main/resources/application.properties` file to review the application configuration, including the Quarkus configuration and the LangChain4j extension settings. 


image::private-docs/application-properties.png[Application properties]

== Testing out the existing chatbot

Now that we've checked out the chatbot, let's test it.

Open a terminal window within Dev Spaces by clicking on the 'hamburger' menu button in the top left, then click on 'Terminal' and finally on 'New Terminal' as seen below:

image::private-docs/new-terminal.png[New Terminal]

In the terminal window that has appeared at the bottom of the editor, run the following command: 

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
./mvnw quarkus:dev
----

This will download some dependencies and start the application in Quarkus Dev Mode.

NOTE: You may get asked to contribute anonymous build time data. It's up to you what to answer, but we recommend answering yes so the Quarkus developers can have valuable performance insights to improve Quarkus even further. :) 

After a minute or 2, depending on network speeds, your application will be up and running:

image::private-docs/quarkus-dev.png[Quarkus dev]

[start=2]
Go ahead and click the "Open In New Tab" button that shows up in the bottom right. Confirm that you want to open the app in the following dialog, after which you should see the Parasol UI in the new tab.

image::private-docs/parasol-ui.png[Parasol UI]

[start=4]
Click on the first claim with number "CLM195501" to open the claim, and then on the chat icon in the bottom right corner to open the chat interface.

image::devhub/claim_view.png[Chat interface]

[start=4]
. In the chat interface, try asking the following questions about a specific claim:
* "What is the status of this claim?"
* "When was the incident reported?"
* "What is the claimed amount?"

image::devhub/chatbot_query.png[Chatbot questions]

You should notice that the chatbot can answer these questions based on the claim context we provided. Now, let's ask a more complex question that requires knowledge of Parasol's policies:

[start=5]
Ask the chatbot: "Should this claim be approved based on Parasol's policies?"

image::private-docs/chat-policies-unknown.png[Chatbot questions about policies]

You'll observe that the chatbot struggles with this question, as it doesn't have access to Parasol's specific policies. If only there was a way to automatically retrieve this information and provide it to the chatbot!

== Embedding Documents with RAG

Retrieval-Augmented Generation (RAG) is a technique that enhances language models by providing them with relevant information retrieved from a knowledge base. This is particularly useful when dealing with domain-specific knowledge or private data. 

=== When to use RAG vs fine-tuning
Use Retrieval-Augmented Generation (RAG) when you need to access a dynamic knowledge base in real-time, especially for tasks that involve varied or constantly updating information. RAG is ideal if you require scalability, need to handle out-of-domain queries, or want to deploy quickly without the resource demands of fine-tuning - which often requires specialized knowledge of working with AI models, something application developers often don't possess.

On the other hand, choose fine-tuning when your task is specialized and you need precise control over the model's behavior. Fine-tuning is better suited for homogeneous data, offline or low-latency applications, and situations where security or compliance requires all data to be embedded within the model. It's also preferable when you have a well-defined use case with specific task requirements.

=== Add Parasol-specific policies to the LLM's knowledge base with RAG

While we could use a database to store (vectorized) data to use with RAG, we can also simply specify a directory where text-based files are stored. We can then parse this data, vectorize it and pass it along to our LLM calls. This process is made very easy with the aptly named "Easy RAG" extension in Quarkus. 

To add this extension, run the following command:

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
./mvnw quarkus:add-extension -Dextension=easy-rag
----

You will see that a new extension was added to your application:

image::private-docs/quarkus-easy-rag.png[Quarkus Easy Rag Extension added]

We have already added the policy document (policy-info.pdf) in the app/src/main/resources/policies folder. We need to tell the Easy Rag extension where to find it by adding the following line to your app/src/main/resources/application.properties:

[.console-input]
[source,java,subs="+attributes,macros+"]
----
quarkus.langchain4j.easy-rag.path=src/main/resources/policies
----

That's all there is to it! Now when we reload the application, it will parse the document and vectorize it into an in-memory embedding store that will be used by the AI calls to the LLM.

NOTE: Of course this is a simple use case with a document loaded into an in-memory embedding store. https://docs.quarkiverse.io/quarkus-langchain4j/dev/easy-rag.html[Click here] If you would like to learn more about Easy Rag and embedding models 

Let's reload the browser window to make sure Quarkus Dev mode picks up the changes. 

Now ask the same questions in the chat window, eg.: "Should this claim be approved based on Parasol's policies?". This time the bot should be able to answer the questions with accurate information based on the policies document!


== Build a tool/agent to notify the user by email an update to their claim

Until now we have had fairly straightforward interactions with the AI LLM model, in that we have asked it questions and it responded with some text and it was up to us to interpret the result. 
Wouldn't it be nice if we could instruct the model to actually call some code in our application and "do" something? That's what the "Tool" concept is all about.

In this section we're going to instruct the LLM to call a piece of code that will actually send a notification email when a claim status changes.

Add the mailer and mailpit extensions to the Quarkus application by issuing the following command in your DevSpaces terminal. (if you still have the Quarkus Dev mode running, that's fine. Just open an additional terminal to send the below command)

[.console-input]
[source,bash,subs="+attributes,macros+"]
----
./mvnw quarkus:add-extension -D"extensions=mailpit,mailer"
----

Now let's create a new NotificationService class that will have the functionality to send an email. Create a new file "NotificationService.java" in the 'ai' folder. 

Paste the following content in the file:

[.console-input]
[source,java,subs="+attributes,macros+"]
----
package org.parasol.ai;

import java.util.Optional;

import jakarta.enterprise.context.ApplicationScoped;
import jakarta.inject.Inject;
import jakarta.transaction.Transactional;

import org.parasol.model.Claim;

import io.quarkus.mailer.Mail;
import io.quarkus.mailer.Mailer;

import dev.langchain4j.agent.tool.Tool;

@ApplicationScoped
public class NotificationService {
	static final String INVALID_STATUS = "Status \"%s\" is not a valid status";
	static final String NOTIFICATION_SUCCESS = "%s (claim number %s) has been notified of status update \"%s\"";
	static final String NOTIFICATION_NO_CLAIMANT_FOUND = "No claim record found in the database for the given claim";
	static final String MESSAGE_FROM = "noreply@parasol.com";
	static final String MESSAGE_SUBJECT = "Update to your claim";
	static final String MESSAGE_BODY = """
		Dear %s,
		
		This is an official communication from the Parasol Insurance Claims Department. We wanted to let you know that your claim (claim # %s) has changed status to "%s".
		
		Sincerely,
		Parasoft Insurance Claims Department
		
		--------------------------------------------
		Please note this is an unmonitored email box.
		Should you choose to reply, nobody (not even an AI bot) will see your message.
		Call a real human should you have any questions. 1-800-CAR-SAFE.
		""";

	@Inject
	Mailer mailer;

	@Tool("update claim status") <1>
	@Transactional
	public String updateClaimStatus(long claimId, String status) {
		// We only want to actually do something if the passed in status has at least 3 characters
		return Optional.ofNullable(status)
			.filter(s -> s.trim().length() > 2)
			.map(s -> updateStatus(claimId, s))
			.orElse(INVALID_STATUS.formatted(status));
	}

	private String updateStatus(long claimId, String status) {
		// We only want to actually do something if there is a corresponding claim in the database for the given claimId
		return Claim.<Claim>findByIdOptional(claimId)
			.map(claim -> updateStatus(claim, status))
			.orElse(NOTIFICATION_NO_CLAIMANT_FOUND);
	}

	private String updateStatus(Claim claim, String status) {
		// Capitalize the first letter
		claim.status = status.trim().substring(0, 1).toUpperCase() + status.trim().substring(1);

		// Save the claim with updated status
		Claim.persist(claim);

		// Send the email
		sendEmail(claim);

		// Return a note to the AI
		return NOTIFICATION_SUCCESS.formatted(claim.emailAddress, claim.claimNumber, claim.status);
	}

	private void sendEmail(Claim claim) {
		// Create the email
		var email = Mail.withText(
			claim.emailAddress,
				MESSAGE_SUBJECT,
				MESSAGE_BODY.formatted(claim.clientName, claim.claimNumber, claim.status)
			)
			.setFrom(MESSAGE_FROM);

		// Send the email to the user
		this.mailer.send(email);
	}
}
----
<1> The @Tool annotation's text content is parsed by the LangChain4j extension and interpreted by the LLM

There is a fair bit of code in this file, but the main thing you should pay attention to is the @Tool annotation with the instruction "update claim status". This piece of natural language text you add to the annotation is interpreted by the LLM, which will now know that if you tell it to eg. "update the claim status of my case", it should call the "updateClaimStatus" method with given parameters.

To wire everything up, we will need to tell the AI Service about this tool. In the app/src/main/java/org/parasol/ai folder, open the ClaimService class again, and find the @RegisterAiService annotation on line 11. You will need to register the NotificationService class as a tool. Go ahead and replace the existing line with the following:

[.console-input]
[source,java,subs="+attributes,macros+"]
----
@RegisterAiService(modelName = "parasol-chat", tools = NotificationService.class)
----

By doing this we have now registered the NotificationService file as class that contains one or more @Tool annotated methods.

Let's try it out! Go back to the browser and refresh the /ClaimDetail/1[claim page for claim 195501]. Open the chat interface again and this time tell the chat assistant to "Update the claim status". After a few moment you should see that the chatbot answers, telling you that it updated the status and sent an email to the customer.

image::private-docs/chat-response-email.png[Chatbot response]

Since we're running this exercise in Quarkus Dev Mode, we can actually test if the email functionality actually works, thanks to the MailPit extension which provides a Quarkus Dev Service with a mock email server. 

Go to the Quarkus Dev UI by pressing the 'w' key from the quarkus dev terminal (or go directly to the https://parasol-app-{user}-dev-parasol-app-{user}-dev.{openshift_cluster_ingress_domain}/q/dev-ui[Quarkus Dev UI^] in your browser). 

image::private-docs/quarkus-dev-ui.png[Quarkus Dev UI]

Find the "Mailpit" section and click on the https://parasol-app-{user}-dev-parasol-app-{user}-dev.{openshift_cluster_ingress_domain}/q/mailpit/[link] next to "Mailpit UI" and you will see a new email that was sent thanks to our newly added functionality!

image::private-docs/mailpit.png[Mailpit UI]




== Conclusion

We hope you have enjoyed this module!

Here is a quick summary of what we have learned:

- TBD
- TBD
- TBD

// .If you've NOT already done the steps in accessing Red Hat Developer Hub and Red Hat Dev Spaces, please follow the instructions in the next section. Otherwise, you can skip ahead to the *Instantiate Developer Hub template* section.
// [%collapsible]
// ======
// include::module-devhub-preq.adoc[]
// ======